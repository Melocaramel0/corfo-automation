# üí∞ Control de Costos - Generaci√≥n de Informes PDF

## ‚úÖ Protecciones Implementadas

He implementado **m√∫ltiples capas de protecci√≥n** para evitar gastos inesperados:

### 1. L√≠mites de Tokens Estrictos

```typescript
MAX_OUTPUT: 3000 tokens        // M√°ximo de tokens generados (informe)
MAX_INPUT_CONTEXT: 8000 tokens // M√°ximo de contexto de entrada
WARNING_INPUT: 5000 tokens      // Advertencia si el input es grande
```

### 2. Protecciones Autom√°ticas

- ‚úÖ **L√≠mite de salida**: M√°ximo 3000 tokens de informe generado
- ‚úÖ **Truncamiento autom√°tico**: Si el contexto supera 8000 tokens, se trunca autom√°ticamente
- ‚úÖ **Advertencias**: Muestra alertas si el input es grande
- ‚úÖ **Estimaci√≥n de costos**: Calcula y muestra el costo aproximado antes de generar

### 3. Monitoreo en Consola

Ver√°s mensajes como:
```
‚ö†Ô∏è Advertencia: Input grande (~6000 tokens estimados). Costo estimado: ~$0.0045
‚úÖ Usando max_completion_tokens (2875 tokens generados)
```

## üíµ Costos Estimados por Informe

### Para GPT-4o-mini (tu modelo):
- **Input**: $0.15 por 1M tokens
- **Output**: $0.60 por 1M tokens

### Ejemplo Real:
- **Input t√≠pico**: ~3,000 tokens ‚Üí ~$0.00045
- **Output m√°ximo**: 3,000 tokens ‚Üí ~$0.0018
- **Costo total por informe**: ~$0.002 - $0.003 (menos de 1 centavo)

### Escenario de Uso Normal:
- **100 informes**: ~$0.20 - $0.30
- **1,000 informes**: ~$2.00 - $3.00
- **10,000 informes**: ~$20 - $30

## üõ°Ô∏è Protecciones Adicionales

### Protecci√≥n 1: L√≠mite Absoluto de Salida
Aunque el modelo no soporte l√≠mites expl√≠citos, **siempre limitamos a 3000 tokens** en las estrategias 1 y 2.

### Protecci√≥n 2: Truncamiento Inteligente
Si el JSON es muy grande (>8000 tokens de contexto), el sistema autom√°ticamente:
1. Trunca el contexto
2. Mantiene la informaci√≥n m√°s importante
3. Muestra advertencia en consola

### Protecci√≥n 3: Monitoreo de Uso Real
Despu√©s de cada generaci√≥n, se muestra:
- Tokens de entrada usados (desde la respuesta de Azure)
- Tokens de salida generados
- Advertencia si supera l√≠mites

### Protecci√≥n 4: Sin Reintentos Autom√°ticos
Si falla una generaci√≥n, **NO se reintenta autom√°ticamente**. Esto previene m√∫ltiples cargos por error.

## üìä Casos de Uso y Costos

### Caso 1: Informe Normal (11 pasos, ~200 campos)
- Input: ~2,500 tokens
- Output: ~2,000 tokens
- **Costo**: ~$0.0015 (~0.15 centavos)

### Caso 2: Informe Grande (muchos errores, contexto extenso)
- Input: ~5,000 tokens (con advertencia)
- Output: ~3,000 tokens (l√≠mite m√°ximo)
- **Costo**: ~$0.003 (~0.3 centavos)

### Caso 3: Informe Muy Grande (se trunca autom√°ticamente)
- Input: ~8,000 tokens (truncado a 8,000)
- Output: ~3,000 tokens
- **Costo**: ~$0.0045 (~0.45 centavos)

## ‚öôÔ∏è C√≥mo Ajustar los L√≠mites (Si Necesitas)

Si quieres l√≠mites m√°s estrictos o m√°s permisivos, edita `ai/generadorInforme.ts`:

```typescript
const LIMITES_TOKENS = {
  MAX_OUTPUT: 2000,        // Reducir para ahorrar m√°s
  MAX_INPUT_CONTEXT: 6000,  // Reducir contexto m√°ximo
  WARNING_INPUT: 4000,      // Advertencia m√°s temprana
} as const;
```

### Recomendaciones:
- **Para ahorrar dinero**: Reduce `MAX_OUTPUT` a 2000 tokens
- **Para informes m√°s detallados**: Aumenta `MAX_OUTPUT` a 4000 tokens (aumenta costo ~33%)
- **Para JSONs muy grandes**: Aumenta `MAX_INPUT_CONTEXT` a 10000 tokens

## üö® Alertas y Advertencias

### Advertencia de Input Grande
Si el contexto supera 5000 tokens, ver√°s:
```
‚ö†Ô∏è Advertencia: Input grande (~6000 tokens estimados). Costo estimado: ~$0.0045
```
**Acci√≥n**: Revisa si realmente necesitas toda esa informaci√≥n en el informe.

### Advertencia de Truncamiento
Si el contexto supera 8000 tokens, ver√°s:
```
‚ö†Ô∏è Contexto muy grande (9000 tokens), optimizando...
```
**Acci√≥n**: El sistema ya est√° manej√°ndolo autom√°ticamente truncando.

### Advertencia de Output Grande (solo en estrategia 3)
Si el output supera 3000 tokens, ver√°s:
```
‚ö†Ô∏è Advertencia: Respuesta grande (3500 tokens). Considera reducir el tama√±o del contexto.
```
**Acci√≥n**: Considera reducir `MAX_INPUT_CONTEXT` o `MAX_OUTPUT`.

## üí° Mejores Pr√°cticas para Ahorrar

1. **Mant√©n los l√≠mites actuales** - Ya est√°n optimizados
2. **Revisa advertencias** - Si ves muchas, considera ajustar
3. **Monitorea el uso real** - Revisa Azure Portal peri√≥dicamente
4. **Usa l√≠mites de Azure** - Configura l√≠mites de gasto en Azure Portal

## üîí L√≠mites de Azure Portal (Recomendado)

**Adem√°s de las protecciones en c√≥digo**, configura l√≠mites en Azure:

1. Ve a **Azure Portal** ‚Üí Tu recurso de Azure OpenAI
2. **Cost Management** ‚Üí **Budgets**
3. Crea un presupuesto mensual (ej: $10, $50, $100)
4. Configura alertas cuando alcances 50%, 80%, 100%

Esto es una **capa adicional de seguridad** fuera del c√≥digo.

## üìà Monitoreo Continuo

Cada ejecuci√≥n muestra:
```
‚úÖ Usando max_completion_tokens (2875 tokens generados)
```

Puedes rastrear:
- Tokens promedio por informe
- Costo promedio por informe
- Total de informes generados

## ‚úÖ Resumen

- ‚úÖ **L√≠mite m√°ximo de salida**: 3000 tokens (protegido en todas las estrategias)
- ‚úÖ **L√≠mite m√°ximo de entrada**: 8000 tokens (se trunca si es mayor)
- ‚úÖ **Advertencias tempranas**: Si el input supera 5000 tokens
- ‚úÖ **Sin reintentos**: No genera m√∫ltiples cargos por error
- ‚úÖ **Costo estimado por informe**: ~$0.002 - $0.004 (menos de 0.5 centavos)
- ‚úÖ **Seguro para uso normal**: 1000 informes = ~$2-3

**Con estas protecciones, es pr√°cticamente imposible tener un gasto inesperado grande.**

